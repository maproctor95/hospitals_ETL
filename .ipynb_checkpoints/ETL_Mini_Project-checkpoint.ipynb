{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the crowdfunding.xlsx Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>ZIP4</th>\n",
       "      <th>...</th>\n",
       "      <th>VAL_DATE</th>\n",
       "      <th>WEBSITE</th>\n",
       "      <th>STATE_ID</th>\n",
       "      <th>ALT_NAME</th>\n",
       "      <th>ST_FIPS</th>\n",
       "      <th>OWNER</th>\n",
       "      <th>TTL_STAFF</th>\n",
       "      <th>BEDS</th>\n",
       "      <th>TRAUMA</th>\n",
       "      <th>HELIPAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-94.945477</td>\n",
       "      <td>29.747620</td>\n",
       "      <td>8497</td>\n",
       "      <td>76777520</td>\n",
       "      <td>HOUSTON METHODIST SAN JACINTO HOSPITAL ALEXANDER CAMPUS</td>\n",
       "      <td>1700 JAMES BOWIE DRIVE</td>\n",
       "      <td>BAYTOWN</td>\n",
       "      <td>TX</td>\n",
       "      <td>77520</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-12-18T00:00:00.000Z</td>\n",
       "      <td>http://www.houstonmethodist.org/locations/san-jacinto-baytown/</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NON-PROFIT</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-82.881843</td>\n",
       "      <td>40.027143</td>\n",
       "      <td>8498</td>\n",
       "      <td>129043230</td>\n",
       "      <td>WOODS AT PARKSIDE,THE</td>\n",
       "      <td>349 OLDE RIDENOUR ROAD</td>\n",
       "      <td>COLUMBUS</td>\n",
       "      <td>OH</td>\n",
       "      <td>43230</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-04-26T00:00:00.000Z</td>\n",
       "      <td>http://www.thewoodsatparkside.com/</td>\n",
       "      <td>1815</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>39.0</td>\n",
       "      <td>PROPRIETARY</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-84.168027</td>\n",
       "      <td>39.774242</td>\n",
       "      <td>8499</td>\n",
       "      <td>130045404</td>\n",
       "      <td>DAYTON CHILDREN'S HOSPITAL</td>\n",
       "      <td>ONE CHILDRENS PLAZA</td>\n",
       "      <td>DAYTON</td>\n",
       "      <td>OH</td>\n",
       "      <td>45404</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-04-26T00:00:00.000Z</td>\n",
       "      <td>http://www.childrensdayton.org/cms/home/index.html</td>\n",
       "      <td>1411</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NON-PROFIT</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>PEDIATRIC LEVEL II</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-80.632972</td>\n",
       "      <td>41.005169</td>\n",
       "      <td>8500</td>\n",
       "      <td>128844512</td>\n",
       "      <td>VIBRA HOSPITAL OF MAHONING VALLEY</td>\n",
       "      <td>8049 SOUTH AVENUE</td>\n",
       "      <td>BOARDMAN</td>\n",
       "      <td>OH</td>\n",
       "      <td>44512</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-04-26T00:00:00.000Z</td>\n",
       "      <td>http://www.mahoningvalleyhospital.com/</td>\n",
       "      <td>1428</td>\n",
       "      <td>MAHONING VALLEY HOSPITAL BOARDMAN CAMPUS</td>\n",
       "      <td>39.0</td>\n",
       "      <td>PROPRIETARY</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-84.199398</td>\n",
       "      <td>39.747740</td>\n",
       "      <td>8501</td>\n",
       "      <td>129845417</td>\n",
       "      <td>HAVEN BEHAVIORAL SENIOR CARE OF DAYTON</td>\n",
       "      <td>ONE ELIZABETH PLACE,E3 SUITE A</td>\n",
       "      <td>DAYTON</td>\n",
       "      <td>OH</td>\n",
       "      <td>45417</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-04-26T00:00:00.000Z</td>\n",
       "      <td>https://dayton.havenbehavioral.com/</td>\n",
       "      <td>1506</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>39.0</td>\n",
       "      <td>PROPRIETARY</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X          Y  OBJECTID         ID  \\\n",
       "0 -94.945477  29.747620      8497   76777520   \n",
       "1 -82.881843  40.027143      8498  129043230   \n",
       "2 -84.168027  39.774242      8499  130045404   \n",
       "3 -80.632972  41.005169      8500  128844512   \n",
       "4 -84.199398  39.747740      8501  129845417   \n",
       "\n",
       "                                                      NAME  \\\n",
       "0  HOUSTON METHODIST SAN JACINTO HOSPITAL ALEXANDER CAMPUS   \n",
       "1                                    WOODS AT PARKSIDE,THE   \n",
       "2                               DAYTON CHILDREN'S HOSPITAL   \n",
       "3                        VIBRA HOSPITAL OF MAHONING VALLEY   \n",
       "4                   HAVEN BEHAVIORAL SENIOR CARE OF DAYTON   \n",
       "\n",
       "                          ADDRESS      CITY STATE    ZIP           ZIP4  ...  \\\n",
       "0          1700 JAMES BOWIE DRIVE   BAYTOWN    TX  77520  NOT AVAILABLE  ...   \n",
       "1          349 OLDE RIDENOUR ROAD  COLUMBUS    OH  43230  NOT AVAILABLE  ...   \n",
       "2             ONE CHILDRENS PLAZA    DAYTON    OH  45404  NOT AVAILABLE  ...   \n",
       "3               8049 SOUTH AVENUE  BOARDMAN    OH  44512  NOT AVAILABLE  ...   \n",
       "4  ONE ELIZABETH PLACE,E3 SUITE A    DAYTON    OH  45417  NOT AVAILABLE  ...   \n",
       "\n",
       "                   VAL_DATE  \\\n",
       "0  2017-12-18T00:00:00.000Z   \n",
       "1  2018-04-26T00:00:00.000Z   \n",
       "2  2018-04-26T00:00:00.000Z   \n",
       "3  2018-04-26T00:00:00.000Z   \n",
       "4  2018-04-26T00:00:00.000Z   \n",
       "\n",
       "                                                          WEBSITE  \\\n",
       "0  http://www.houstonmethodist.org/locations/san-jacinto-baytown/   \n",
       "1                              http://www.thewoodsatparkside.com/   \n",
       "2              http://www.childrensdayton.org/cms/home/index.html   \n",
       "3                          http://www.mahoningvalleyhospital.com/   \n",
       "4                             https://dayton.havenbehavioral.com/   \n",
       "\n",
       "        STATE_ID                                  ALT_NAME ST_FIPS  \\\n",
       "0  NOT AVAILABLE                             NOT AVAILABLE    48.0   \n",
       "1           1815                             NOT AVAILABLE    39.0   \n",
       "2           1411                             NOT AVAILABLE    39.0   \n",
       "3           1428  MAHONING VALLEY HOSPITAL BOARDMAN CAMPUS    39.0   \n",
       "4           1506                             NOT AVAILABLE    39.0   \n",
       "\n",
       "         OWNER TTL_STAFF   BEDS              TRAUMA        HELIPAD  \n",
       "0   NON-PROFIT    -999.0  182.0       NOT AVAILABLE              Y  \n",
       "1  PROPRIETARY    -999.0   50.0       NOT AVAILABLE  NOT AVAILABLE  \n",
       "2   NON-PROFIT    -999.0  155.0  PEDIATRIC LEVEL II              Y  \n",
       "3  PROPRIETARY    -999.0   45.0       NOT AVAILABLE  NOT AVAILABLE  \n",
       "4  PROPRIETARY    -999.0   32.0       NOT AVAILABLE  NOT AVAILABLE  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data into a Pandas DataFrame\n",
    "Hospital_info_df = pd.read_csv('Data/Hospitals.csv')\n",
    "Hospital_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7570 entries, 0 to 7569\n",
      "Data columns (total 34 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   X           7570 non-null   float64\n",
      " 1   Y           7570 non-null   float64\n",
      " 2   OBJECTID    7570 non-null   int64  \n",
      " 3   ID          7570 non-null   int64  \n",
      " 4   NAME        7570 non-null   object \n",
      " 5   ADDRESS     7570 non-null   object \n",
      " 6   CITY        7570 non-null   object \n",
      " 7   STATE       7570 non-null   object \n",
      " 8   ZIP         7570 non-null   int64  \n",
      " 9   ZIP4        7570 non-null   object \n",
      " 10  TELEPHONE   7570 non-null   object \n",
      " 11  TYPE        7570 non-null   object \n",
      " 12  STATUS      7570 non-null   object \n",
      " 13  POPULATION  7570 non-null   int64  \n",
      " 14  COUNTY      7570 non-null   object \n",
      " 15  COUNTYFIPS  7570 non-null   object \n",
      " 16  COUNTRY     7570 non-null   object \n",
      " 17  LATITUDE    7570 non-null   float64\n",
      " 18  LONGITUDE   7570 non-null   float64\n",
      " 19  NAICS_CODE  7570 non-null   int64  \n",
      " 20  NAICS_DESC  7570 non-null   object \n",
      " 21  SOURCE      7570 non-null   object \n",
      " 22  SOURCEDATE  7570 non-null   object \n",
      " 23  VAL_METHOD  7570 non-null   object \n",
      " 24  VAL_DATE    7570 non-null   object \n",
      " 25  WEBSITE     7570 non-null   object \n",
      " 26  STATE_ID    7570 non-null   object \n",
      " 27  ALT_NAME    7569 non-null   object \n",
      " 28  ST_FIPS     7569 non-null   float64\n",
      " 29  OWNER       7569 non-null   object \n",
      " 30  TTL_STAFF   7569 non-null   float64\n",
      " 31  BEDS        7569 non-null   float64\n",
      " 32  TRAUMA      7569 non-null   object \n",
      " 33  HELIPAD     7569 non-null   object \n",
      "dtypes: float64(7), int64(5), object(22)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get a brief summary of the crowdfunding_info DataFrame.\n",
    "Hospital_info_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Category and Subcategory DataFrames\n",
    "---\n",
    "**Create a Category DataFrame that has the following columns:**\n",
    "- A \"category_id\" column that is numbered sequential form 1 to the length of the number of unique categories.\n",
    "- A \"category\" column that has only the categories.\n",
    "\n",
    "Export the DataFrame as a `category.csv` CSV file.\n",
    "\n",
    "**Create a SubCategory DataFrame that has the following columns:**\n",
    "- A \"subcategory_id\" column that is numbered sequential form 1 to the length of the number of unique subcategories.\n",
    "- A \"subcategory\" column that has only the subcategories. \n",
    "\n",
    "Export the DataFrame as a `subcategory.csv` CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the crowdfunding_info_df columns.\n",
    "crowdfunding_info_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the category and subcategory values to category and subcategory columns.\n",
    "crowdfunding_info_df[[\"category\",\"subcategory\"]]  = crowdfunding_info_df[\"category & sub-category\"].str.split('/', n=1, expand=True)\n",
    "crowdfunding_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique categories and subcategories in separate lists.\n",
    "categories = crowdfunding_info_df[\"category\"].unique()\n",
    "subcategories = crowdfunding_info_df[\"subcategory\"].unique()\n",
    "\n",
    "print(categories)\n",
    "print(subcategories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of distinct values in the categories and subcategories lists.\n",
    "print(len(categories))\n",
    "print(len(subcategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create numpy arrays from 1-9 for the categories and 1-24 for the subcategories.\n",
    "category_ids = np.arange(1, 10)\n",
    "subcategory_ids = np.arange(1, 25)\n",
    "\n",
    "print(category_ids)\n",
    "print(subcategory_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a list comprehension to add \"cat\" to each category_id. \n",
    "cat_ids = [\"cat\" + str(cat_id) for cat_id in category_ids]\n",
    "# Use a list comprehension to add \"subcat\" to each subcategory_id.    \n",
    "scat_ids = [\"subcat\" + str(scat_id) for scat_id in subcategory_ids ]\n",
    "    \n",
    "print(cat_ids)\n",
    "print(scat_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a category DataFrame with the category_id array as the category_id and categories list as the category name.\n",
    "category_df = pd.DataFrame({\n",
    "    \"category_id\": cat_ids,\n",
    "    \"category\" : categories\n",
    "})\n",
    "    \n",
    "# Create a category DataFrame with the subcategory_id array as the subcategory_id and subcategories list as the subcategory name. \n",
    "subcategory_df = pd.DataFrame({\n",
    "    \"subcategory_id\": scat_ids,\n",
    "    \"subcategory\" : subcategories\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcategory_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export categories_df and subcategories_df as CSV files.\n",
    "category_df.to_csv(\"Resources/category.csv\", index=False)\n",
    "\n",
    "subcategory_df.to_csv(\"Resources/subcategory.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Campaign DataFrame\n",
    "----\n",
    "**Create a Campaign DataFrame that has the following columns:**\n",
    "- The \"cf_id\" column.\n",
    "- The \"contact_id\" column.\n",
    "- The “company_name” column.\n",
    "- The \"blurb\" column is renamed as \"description.\"\n",
    "- The \"goal\" column.\n",
    "- The \"goal\" column is converted to a `float` datatype.\n",
    "- The \"pledged\" column is converted to a `float` datatype. \n",
    "- The \"backers_count\" column. \n",
    "- The \"country\" column.\n",
    "- The \"currency\" column.\n",
    "- The \"launched_at\" column is renamed as \"launch_date\" and converted to a datetime format. \n",
    "- The \"deadline\" column is renamed as \"end_date\" and converted to a datetime format.\n",
    "- The \"category_id\" with the unique number matching the “category_id” from the category DataFrame. \n",
    "- The \"subcategory_id\" with the unique number matching the “subcategory_id” from the subcategory DataFrame.\n",
    "- And, create a column that contains the unique four-digit contact ID number from the `contact.xlsx` file.\n",
    " \n",
    "\n",
    "Then export the DataFrame as a `campaign.csv` CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the crowdfunding_info_df DataFrame name campaign_df. \n",
    "campaign_df = crowdfunding_info_df.copy()\n",
    "campaign_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the blurb, launched_at, and deadline columns.\n",
    "campaign_df = campaign_df.rename(columns={'blurb': 'description', 'launched_at': 'launched_date', 'deadline': 'end_date'})\n",
    "campaign_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the goal and pledged columns to a `float` data type.\n",
    "campaign_df[[\"goal\",\"pledged\"]] = campaign_df[[\"goal\",\"pledged\"]].astype(float)\n",
    "campaign_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the datatypes\n",
    "campaign_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the launched_date and end_date columns to datetime format\n",
    "from datetime import datetime as dt\n",
    "campaign_df[\"launched_date\"] = pd.to_datetime(campaign_df[\"launched_date\"], unit='s').dt.strftime('%Y-%m-%d') \n",
    "campaign_df[\"end_date\"] = pd.to_datetime(campaign_df[\"end_date\"], unit='s').dt.strftime('%Y-%m-%d')\n",
    "campaign_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Merge the campaign_df with the category_df on the \"category\" column and \n",
    "# the subcategory_df on the \"subcategory\" column.\n",
    "\n",
    "campaign_merged_df = campaign_df.merge(category_df, on='category', how='left').merge(subcategory_df, on='subcategory', how='left')\n",
    "\n",
    "campaign_merged_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unwanted columns\n",
    "campaign_cleaned = campaign_merged_df.drop(['staff_pick', 'spotlight', 'category & sub-category','category', 'subcategory'], axis=1)\n",
    "campaign_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame as a CSV file. \n",
    "campaign_cleaned.to_csv(\"Resources/campaign.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the contacts.xlsx Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into a Pandas DataFrame. Use the `header=2` parameter when reading in the data.\n",
    "contact_info_df = pd.read_excel('Resources/contacts.xlsx', header=3)\n",
    "contact_info_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Contacts DataFrame \n",
    "---\n",
    "**Create a Contacts DataFrame that has the following columns:**\n",
    "- A column named \"contact_id\"  that contains the unique number of the contact person.\n",
    "- A column named \"first_name\" that contains the first name of the contact person.\n",
    "- A column named \"last_name\" that contains the first name of the contact person.\n",
    "- A column named \"email\" that contains the email address of the contact person\n",
    "\n",
    "Then export the DataFrame as a `contacts.csv` CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Use Pandas to create the contacts DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the contact_info_df and convert each row to a dictionary.\n",
    "import json\n",
    "dict_values = []\n",
    "for i, row in contact_info_df.iterrows():\n",
    "    data = row['contact_info']\n",
    "    converted_data = json.loads(data)\n",
    "    row_values = [v for k, v in converted_data.items()]\n",
    "    dict_values.append(row_values)\n",
    "\n",
    "\n",
    "# Print out the list of values for each row.\n",
    "print(dict_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a contact_info DataFrame and add each list of values, i.e., each row \n",
    "# to the 'contact_id', 'name', 'email' columns.\n",
    "contacts_df = pd.DataFrame(dict_values, columns=['contact_id', 'name', 'email'])\n",
    "contacts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the datatypes.\n",
    "contacts_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"first\"name\" and \"last_name\" column with the first and last names from the \"name\" column. \n",
    "contacts_df[[\"first_name\",\"last_name\"]] = contacts_df[\"name\"].str.split(' ', n=1, expand=True)\n",
    "\n",
    "# Drop the contact_name column\n",
    "contacts_df_clean = contacts_df.drop(['name'], axis=1)\n",
    "contacts_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns\n",
    "contacts_df_clean = contacts_df_clean[['contact_id','first_name', 'last_name', 'email']]\n",
    "contacts_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the datatypes one more time before exporting as CSV file.\n",
    "contacts_df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame as a CSV file. \n",
    "contacts_df_clean.to_csv(\"Resources/contacts.csv\", encoding='utf8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Use regex to create the contacts DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_info_df_copy = contact_info_df.copy()\n",
    "contact_info_df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the four-digit contact ID number.\n",
    "contact_info_df_copy['contact_id'] = contact_info_df_copy['contact_info'].str.extract(r'(\\d{4})')\n",
    "contact_info_df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the datatypes.\n",
    "contact_info_df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the \"contact_id\" column to an int64 data type.\n",
    "contact_info_df_copy['contact_id'] = pd.to_numeric(contact_info_df_copy['contact_id'])\n",
    "contact_info_df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the name of the contact and add it to a new column.\n",
    "contact_info_df_copy['name'] = contact_info_df_copy['contact_info'].str.extract(r'([^nameil\"\\s][A-Za-z]+\\s+[A-Za-z]+)')\n",
    "contact_info_df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the email from the contacts and add the values to a new column.\n",
    "contact_info_df_copy['email'] = contact_info_df_copy['contact_info'].str.extract(r'\"(\\S+@\\S+)\"}')\n",
    "contact_info_df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the contact_info_df with the 'contact_id', 'name', 'email' columns.\n",
    "contacts_df_copy2 = contact_info_df_copy[['contact_id', 'name', 'email']].copy()\n",
    "contacts_df_copy2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"first\"name\" and \"last_name\" column with the first and last names from the \"name\" column. \n",
    "contacts_df_copy2[[\"first_name\",\"last_name\"]] = contacts_df_copy2[\"name\"].str.split(' ', n=1, expand=True)\n",
    "\n",
    "# Drop the contact_name column\n",
    "contacts_df_clean2 = contacts_df_copy2.drop(['name'], axis=1)\n",
    "contacts_df_clean2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns\n",
    "contacts_df_clean2 = contacts_df_clean2[['contact_id','first_name', 'last_name', 'email']]\n",
    "contacts_df_clean2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the datatypes one more time before exporting as CSV file.\n",
    "contacts_df_clean2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame as a CSV file. \n",
    "contacts_df_clean.to_csv(\"Resources/contacts.csv\", encoding='utf8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
